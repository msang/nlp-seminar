{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8881a96-801e-4e54-b68f-9706ccdfd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib nltk numpy pandas scikit-learn seaborn spacy stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27447cda-20a4-4a63-a0bb-c48e1beb0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download it_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2303199-6329-420c-bc92-d120cc67d8e7",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4dae1d-c8f1-4f0a-82ea-852a6f8e21ef",
   "metadata": {},
   "source": [
    "The data used in this notebook is available [here](https://live.european-language-grid.eu/catalogue/corpus/7498)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "19219b72-c712-4823-9086-47ccc38574b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hs</th>\n",
       "      <th>stereotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2066</td>\n",
       "      <td>È terrorismo anche questo, per mettere in uno ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2045</td>\n",
       "      <td>@user @user infatti finché ci hanno guadagnato...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>Corriere: Tangenti, Mafia Capitale dimenticata...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1259</td>\n",
       "      <td>@user ad uno ad uno, perché quando i migranti ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>949</td>\n",
       "      <td>Il divertimento del giorno? Trovare i patrioti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>9340</td>\n",
       "      <td>Gli stati nazionali devono essere pronti a rin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>9121</td>\n",
       "      <td>Il ministro dell'interno della Germania #Horst...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>8549</td>\n",
       "      <td>#Salvini: In Italia troppi si sono montati la ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>9240</td>\n",
       "      <td>@user @user Chi giubila in buona fede non ha c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>8000</td>\n",
       "      <td>I giovani cristiani in #Etiopia sono indotti d...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6839 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          full_text  hs  stereotype\n",
       "0     2066  È terrorismo anche questo, per mettere in uno ...   0           0\n",
       "1     2045  @user @user infatti finché ci hanno guadagnato...   0           0\n",
       "2       61  Corriere: Tangenti, Mafia Capitale dimenticata...   0           0\n",
       "3     1259  @user ad uno ad uno, perché quando i migranti ...   0           0\n",
       "4      949  Il divertimento del giorno? Trovare i patrioti...   0           0\n",
       "...    ...                                                ...  ..         ...\n",
       "6834  9340  Gli stati nazionali devono essere pronti a rin...   0           0\n",
       "6835  9121  Il ministro dell'interno della Germania #Horst...   0           0\n",
       "6836  8549  #Salvini: In Italia troppi si sono montati la ...   0           0\n",
       "6837  9240  @user @user Chi giubila in buona fede non ha c...   0           0\n",
       "6838  8000  I giovani cristiani in #Etiopia sono indotti d...   0           1\n",
       "\n",
       "[6839 rows x 4 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hs_dev = pd.read_csv(\"haspeede2_dev_taskAB_anon_revised.tsv\")\n",
    "hs_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb98ef-a63d-492f-a48c-51bc985f0909",
   "metadata": {},
   "source": [
    "* Get label distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9b1b57a4-98b7-474e-9c20-93e7524f7f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HS CLASS DISTRIBUTION \n",
      "(raw) \n",
      "0    4073\n",
      "1    2766\n",
      "Name: hs, dtype: int64 \n",
      "(%) \n",
      "0    0.595555\n",
      "1    0.404445\n",
      "Name: hs, dtype: float64\n",
      "\n",
      "STEREOTYPE CLASS DISTRIBUTION \n",
      "(raw) \n",
      "0    3797\n",
      "1    3042\n",
      "Name: stereotype, dtype: int64 \n",
      "(%) \n",
      "0    0.555198\n",
      "1    0.444802\n",
      "Name: stereotype, dtype: float64\n",
      "\n",
      "CO-OCCURRENCE STATISTICS: \n",
      "hs  stereotype\n",
      "0   0             3049\n",
      "    1             1024\n",
      "1   1             2018\n",
      "    0              748\n",
      "Name: stereotype, dtype: int64 \n",
      "\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "hs_raw = hs_dev.hs.value_counts()\n",
    "hs_norm = hs_dev.hs.value_counts(normalize=True)\n",
    "print(f'HS CLASS DISTRIBUTION \\n(raw) \\n{hs_raw} \\n(%) \\n{hs_norm}')\n",
    "ster_raw = hs_dev.stereotype.value_counts()\n",
    "ster_norm = hs_dev.stereotype.value_counts(normalize=True)\n",
    "print(f'\\nSTEREOTYPE CLASS DISTRIBUTION \\n(raw) \\n{ster_raw} \\n(%) \\n{ster_norm}')\n",
    "hs_ster = hs_dev.groupby('hs')['stereotype'].value_counts()\n",
    "print(f'\\nCO-OCCURRENCE STATISTICS: \\n{hs_ster} \\n')\n",
    "#print(sns.barplot(x=hs_norm.index, y=hs_norm))\n",
    "print(sns.barplot(x=ster_norm.index, y=ster_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b3e59e-37f6-4078-be17-88938fb0bdf1",
   "metadata": {},
   "source": [
    "* Get most frequent terms and n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e5721869-9de4-4e66-9b90-706864ad07f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#find most common bigrams\\nbgs = bigrams(ster_text)\\nfdist = FreqDist(bgs)\\nfdist.most_common(20)\\n\\n#find most common trigrams\\ntgs = trigrams(text)\\nfdist = FreqDist(tgs)\\nfdist.most_common(20)\\n'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk import bigrams, trigrams, FreqDist\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "STOPWORDS = get_stop_words('it') + [\"url\", \"user\", \"@user\"]\n",
    "text = [item for tweet in hs_dev['full_text'] for item in tweet.split(\" \") if item.lower() not in STOPWORDS and item not in string.punctuation]\n",
    "hs_text = [item for tweet in hs_dev[hs_dev.hs == 1]['full_text'] for item in tweet.split(\" \") if item.lower() not in STOPWORDS and item not in string.punctuation]\n",
    "ster_text = [item for tweet in hs_dev[hs_dev.stereotype == 1]['full_text'] for item in tweet.split(\" \") if item.lower() not in STOPWORDS and item not in string.punctuation]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#find most common bigrams\n",
    "bgs = bigrams(ster_text)\n",
    "fdist = FreqDist(bgs)\n",
    "fdist.most_common(20)\n",
    "\n",
    "#find most common trigrams\n",
    "tgs = trigrams(text)\n",
    "fdist = FreqDist(tgs)\n",
    "fdist.most_common(20)\n",
    "\"\"\"\n",
    "#find most common terms\n",
    "fdist = FreqDist(text)\n",
    "fdist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b432c-69c5-4c60-85c9-06a610f04cdc",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing\n",
    "\n",
    "* tokenization\n",
    "* stopwords+punctuation removal\n",
    "* lowercasing\n",
    "* lemmatization\n",
    "* ... and many other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9380db35-ff9a-4b50-8259-8d962b7a355e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hs</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2066</td>\n",
       "      <td>È terrorismo anche questo, per mettere in uno ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>terror mett stat soggezion person rend innocu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2045</td>\n",
       "      <td>@user @user infatti finché ci hanno guadagnato...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>infatt finc guadagn camp rom ok alemann ipocr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>Corriere: Tangenti, Mafia Capitale dimenticata...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corr tangent maf capital dimenticatamazzett bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1259</td>\n",
       "      <td>@user ad uno ad uno, perché quando i migranti ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>quand migrant israel arriv terr canaan fuor ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>949</td>\n",
       "      <td>Il divertimento del giorno? Trovare i patrioti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>divert giorn trov patriot italian innegg rom s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>9340</td>\n",
       "      <td>Gli stati nazionali devono essere pronti a rin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>stat nazional dev esser pront rinunc propr sov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>9121</td>\n",
       "      <td>Il ministro dell'interno della Germania #Horst...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ministr dell'intern german horstseehofer propo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>8549</td>\n",
       "      <td>#Salvini: In Italia troppi si sono montati la ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>salvin ital tropp mont test ringraz dio mes st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>9240</td>\n",
       "      <td>@user @user Chi giubila in buona fede non ha c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>giubil buon fed cap nient purtropp cred buon f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>8000</td>\n",
       "      <td>I giovani cristiani in #Etiopia sono indotti d...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>giovan cristian etiop indott islam convert all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6839 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          full_text  hs  stereotype  \\\n",
       "0     2066  È terrorismo anche questo, per mettere in uno ...   0           0   \n",
       "1     2045  @user @user infatti finché ci hanno guadagnato...   0           0   \n",
       "2       61  Corriere: Tangenti, Mafia Capitale dimenticata...   0           0   \n",
       "3     1259  @user ad uno ad uno, perché quando i migranti ...   0           0   \n",
       "4      949  Il divertimento del giorno? Trovare i patrioti...   0           0   \n",
       "...    ...                                                ...  ..         ...   \n",
       "6834  9340  Gli stati nazionali devono essere pronti a rin...   0           0   \n",
       "6835  9121  Il ministro dell'interno della Germania #Horst...   0           0   \n",
       "6836  8549  #Salvini: In Italia troppi si sono montati la ...   0           0   \n",
       "6837  9240  @user @user Chi giubila in buona fede non ha c...   0           0   \n",
       "6838  8000  I giovani cristiani in #Etiopia sono indotti d...   0           1   \n",
       "\n",
       "                                           preprocessed  \n",
       "0     terror mett stat soggezion person rend innocu ...  \n",
       "1         infatt finc guadagn camp rom ok alemann ipocr  \n",
       "2     corr tangent maf capital dimenticatamazzett bu...  \n",
       "3     quand migrant israel arriv terr canaan fuor ca...  \n",
       "4     divert giorn trov patriot italian innegg rom s...  \n",
       "...                                                 ...  \n",
       "6834  stat nazional dev esser pront rinunc propr sov...  \n",
       "6835  ministr dell'intern german horstseehofer propo...  \n",
       "6836  salvin ital tropp mont test ringraz dio mes st...  \n",
       "6837  giubil buon fed cap nient purtropp cred buon f...  \n",
       "6838  giovan cristian etiop indott islam convert all...  \n",
       "\n",
       "[6839 rows x 5 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, spacy, string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    #remove digits\n",
    "    text = re.sub('\\d+', '', sentence)\n",
    "    #remove extra whitespaces\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    #tokenization\n",
    "    text = word_tokenize(text)\n",
    "    #stopwords/punctuation removal + lowercasing\n",
    "    text = [token.lower() for token in text if token.lower() not in STOPWORDS and token not in string.punctuation]\n",
    "    #lemmatization\n",
    "    #sent = \" \".join(text)\n",
    "    #nlp = spacy.load(\"it_core_news_sm\")\n",
    "    #text = [token.lemma_ for token in nlp(sent)]\n",
    "    #stemming\n",
    "    stemmer = SnowballStemmer('italian')\n",
    "    text = [stemmer.stem(token) for token in text]\n",
    "    #other possible operations: handle emojis/emoticons, hashtags, URLs/email addresses, twitter handles \n",
    "    return \" \".join(text) \n",
    " \n",
    "\n",
    "hs_dev['preprocessed'] = hs_dev['full_text'].apply(lambda x: preprocess(x))\n",
    "hs_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1caa7-5ab1-42b9-b5f3-a8a4bac4a13a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train-Test/Validation split\n",
    "(In this case we already have a held-out test set, but you might want to use a validation set as well for hyper-parameter tuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d73cb891-5037-4849-aa54-c357fa18c73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       terror mett stat soggezion person rend innocu ...\n",
       "1           infatt finc guadagn camp rom ok alemann ipocr\n",
       "2       corr tangent maf capital dimenticatamazzett bu...\n",
       "3       quand migrant israel arriv terr canaan fuor ca...\n",
       "4       divert giorn trov patriot italian innegg rom s...\n",
       "                              ...                        \n",
       "6834    stat nazional dev esser pront rinunc propr sov...\n",
       "6835    ministr dell'intern german horstseehofer propo...\n",
       "6836    salvin ital tropp mont test ringraz dio mes st...\n",
       "6837    giubil buon fed cap nient purtropp cred buon f...\n",
       "6838    giovan cristian etiop indott islam convert all...\n",
       "Name: preprocessed, Length: 6839, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#if you split into train and validation sets:\n",
    "X_train_hs, X_val_hs, y_train_hs, y_val_hs = train_test_split(hs_dev[\"preprocessed\"],hs_dev[\"hs\"],test_size=0.1)\n",
    "\n",
    "#if you just use the whole training set without hyper-parameter tuning:\n",
    "X_train_hs = hs_dev[\"preprocessed\"]\n",
    "y_train_hs = hs_dev[\"hs\"]\n",
    "\n",
    "X_train_hs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f621a0-d7d2-4f5b-a544-0bf49fcbe693",
   "metadata": {},
   "source": [
    "# Feature extraction and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66791ad-6ace-4f3a-bfcd-f2496ecd37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#\"\"\"\n",
    "#create feature vectors\n",
    "count = CountVectorizer(analyzer='word', max_features=5000)\n",
    "count_train = count.fit_transform(X_train_hs)\n",
    "tfidf = TfidfVectorizer(analyzer='word', max_features=5000)\n",
    "tfidf_train = tfidf.fit_transform(X_train_hs)\n",
    "trg = TfidfVectorizer(analyzer='word', ngram_range= (1,3), max_features=5000)\n",
    "trg_train = trg.fit_transform(X_train_hs)\n",
    "\n",
    "#fit the classifier on the training data\n",
    "svm = LinearSVC() # as classifier, we just use a linear SVM with default parameters\n",
    "svm_tfidf = LinearSVC()\n",
    "svm_trg = LinearSVC()\n",
    "svm.fit(count_train, y_train_hs)\n",
    "svm_tfidf.fit(tfidf_train, y_train_hs)\n",
    "svm_trg.fit(trg_train, y_train_hs)\n",
    "#\"\"\"\n",
    "\n",
    "\"\"\" alternative code using make_pipeline:\n",
    "count = CountVectorizer(analyzer='word', max_features=5000)\n",
    "tfidf = TfidfVectorizer(analyzer='word', max_features=5000)\n",
    "tfidf_trg = TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=5000)\n",
    "\n",
    "svm = LinearSVC()  \n",
    "svm_tfidf = LinearSVC()\n",
    "svm_trg = LinearSVC()\n",
    "\n",
    "pipe_count = make_pipeline(count, svm)\n",
    "pipe_tfidf = make_pipeline(tfidf, svm_tfidf)\n",
    "pipe_trigrams = make_pipeline(tfidf_trg, svm_trg)\n",
    "\n",
    "pipe_count.fit(X_train_hs, y_train_hs)\n",
    "pipe_tfidf.fit(X_train_hs, y_train_hs)\n",
    "pipe_trigrams.fit(X_train_hs, y_train_hs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a443801b-8296-4c1f-a3ca-7d2a73ab35a3",
   "metadata": {},
   "source": [
    "# Evaluation and error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d955b2b6-0884-4f54-b505-825e9f019da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT VECTORS: \n",
      "\n",
      "CONFUSION MATRIX \n",
      "[[452 189]\n",
      " [177 445]] \n",
      "\n",
      "EVALUATION METRICS \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71       641\n",
      "           1       0.70      0.72      0.71       622\n",
      "\n",
      "    accuracy                           0.71      1263\n",
      "   macro avg       0.71      0.71      0.71      1263\n",
      "weighted avg       0.71      0.71      0.71      1263\n",
      "\n",
      "TF-IDF VECTORS: \n",
      "\n",
      "CONFUSION MATRIX \n",
      "[[478 163]\n",
      " [153 469]] \n",
      "\n",
      "EVALUATION METRICS \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75       641\n",
      "           1       0.74      0.75      0.75       622\n",
      "\n",
      "    accuracy                           0.75      1263\n",
      "   macro avg       0.75      0.75      0.75      1263\n",
      "weighted avg       0.75      0.75      0.75      1263\n",
      "\n",
      "TF-IDF VECTORS + TRIGRAMS: \n",
      "\n",
      "CONFUSION MATRIX \n",
      "[[448 193]\n",
      " [160 462]] \n",
      "\n",
      "EVALUATION METRICS \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       641\n",
      "           1       0.71      0.74      0.72       622\n",
      "\n",
      "    accuracy                           0.72      1263\n",
      "   macro avg       0.72      0.72      0.72      1263\n",
      "weighted avg       0.72      0.72      0.72      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "hs_test = pd.read_csv(\"haspeede2_reference_taskAB-tweets_anon_revised.tsv\")\n",
    "#hs_test = pd.read_csv(\"haspeede2_reference_taskAB-news_anon_revised.tsv\")\n",
    "hs_test\n",
    "\n",
    "X_test_hs = hs_test['full_text'].apply(lambda x: preprocess(x))\n",
    "y_test_hs = hs_test['hs']\n",
    "\n",
    "#\"\"\"\n",
    "count_test = count.transform(X_test_hs)\n",
    "tfidf_test = tfidf.transform(X_test_hs)\n",
    "trg_test = trg.transform(X_test_hs)\n",
    "\n",
    "y_pred_count = svm.predict(count_test)\n",
    "y_pred_tfidf = svm_tfidf.predict(tfidf_test)\n",
    "y_pred_trg = svm_trg.predict(trg_test)\n",
    "#\"\"\"\n",
    "\"\"\"\n",
    "y_pred_count = pipe_count.predict(X_test_hs)\n",
    "y_pred_tfidf = pipe_tfidf.predict(X_test_hs)\n",
    "y_pred_trg = pipe_trigrams.predict(X_test_hs)\n",
    "\"\"\"\n",
    "\n",
    "print('COUNT VECTORS: \\n\\nCONFUSION MATRIX ')       \n",
    "print(confusion_matrix(y_test_hs, y_pred_count), '\\n') \n",
    "print('EVALUATION METRICS \\n',classification_report(y_test_hs, y_pred_count))\n",
    "print('TF-IDF VECTORS: \\n\\nCONFUSION MATRIX ')       \n",
    "print(confusion_matrix(y_test_hs, y_pred_tfidf), '\\n') \n",
    "print('EVALUATION METRICS \\n',classification_report(y_test_hs, y_pred_tfidf))\n",
    "print('TF-IDF VECTORS + TRIGRAMS: \\n\\nCONFUSION MATRIX ')  \n",
    "print(confusion_matrix(y_test_hs, y_pred_trg), '\\n') \n",
    "print('EVALUATION METRICS \\n',classification_report(y_test_hs, y_pred_trg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a67d8c-aebf-4dd8-9cd4-d7a4c24e523d",
   "metadata": {},
   "source": [
    "Try using visual libraries to explain system's predictions, like [eli5](https://github.com/TeamHG-Memex/eli5) or \n",
    "[LIME](https://marcotcr.github.io/lime/). Both packages provide nice tutorials. Here an example using eli5 (source available [here](https://github.com/TeamHG-Memex/eli5/blob/master/notebooks/Debugging%20scikit-learn%20text%20classification%20pipeline.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "13950d0d-2c30-4891-858b-d9a1ad23705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manzu\\miniconda3\\envs\\jun2022\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.841\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mussulman\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.19%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.802\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ripul\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.510\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        islam\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.302\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        bast\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.70%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.121\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        delinquent\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.01%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.064\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        fecc\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.983\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        charliehebd\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.99%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.885\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        fancul\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.835\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        merd\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.27%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2485 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.84%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2483 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.912\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        nomad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.show_weights(svm_tfidf, vec=tfidf, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13970cdb-0794-420a-90e7-d61a3675b44b",
   "metadata": {},
   "source": [
    "Try using the best-performing model with some brand new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "02207713-d85c-4b97-8774-2ca74a09c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stranier cas'] [1]\n"
     ]
    }
   ],
   "source": [
    "sent = [preprocess(\"stranieri tutti a casa\")] #put here some made-up sentence, just to see how the model goes\n",
    "new = tfidf.transform(sent)\n",
    "y_pred_tfidf = svm_tfidf.predict(new)\n",
    "print(sent, y_pred_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d1f7b-92db-4d92-9163-10bea9d08fdf",
   "metadata": {},
   "source": [
    "To perform <b>error analysis</b>:\n",
    "* select a sample of mislabeled data\n",
    "* compare results with gold annotation\n",
    "* get insights on possible causes of misclassification (also defining patterns, if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f152d-260e-452a-bb91-55f05f2b53b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
